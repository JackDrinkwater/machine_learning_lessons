{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import SCORERS, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/users/stanislav/data/consumption/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('TARGET', axis=1), train.TARGET,\n",
    "                                                    train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### When I had done many prints of metrics, I guessed that I could  make some functions, so then I wrote it here below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_result(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('accuracy: ', accuracy_score(y_test, model.predict(X_test)))\n",
    "    print('recall:   ', recall_score(y_test, model.predict(X_test)))\n",
    "    print('f1:       ', f1_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model):\n",
    "    return(pd.DataFrame(model.feature_importances_, index=X_train.columns, \n",
    "           columns=['Importance']).sort_values(by='Importance', ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defalut models - xgb and lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9598351311058494\n",
      "recall:    0.001092896174863388\n",
      "f1:        0.0021786492374727667\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "fit_and_result(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9593966500043848\n",
      "recall:    0.003278688524590164\n",
      "f1:        0.006437768240343348\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(random_state=42)\n",
    "\n",
    "fit_and_result(lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters - complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'num_leaves' : [7, 15, 31, 63],\n",
    "              'max_depth' : [3, 4, 5, 6, -1],\n",
    "              'reg_alpha' : range(0, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher = GridSearchCV(estimator=lgb, param_grid=param_grid, cv=5, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 23.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9594404981145312\n",
      "recall:    0.00546448087431694\n",
      "f1:        0.0106951871657754\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(grid_searcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': -1, 'num_leaves': 63, 'reg_alpha': 0}, 0.022947909852012758)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best 'num_leaves' is on high border of given param_grid\n",
    "# that means that better parameter may be higher and\n",
    "# out of given grid \n",
    "grid_searcher.best_params_, grid_searcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameteres - convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of estimators from 100 (default) to 200\n",
    "lgb2 = LGBMClassifier(random_state=42, max_depth=-1, num_leaves=63, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.logspace(-3, 0, 10) = array([0.001, 0.00215443, 0.00464159, 0.01, 0.02154435,\n",
    "#                                 0.04641589, 0.1, 0.21544347, 0.46415888, 1.0])\n",
    "param_grid2 = {'learning_rate' : np.logspace(-3, 0, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher2 = GridSearchCV(estimator=lgb2, param_grid=param_grid2, cv=5, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 18.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9337455055687099\n",
      "recall:    0.15737704918032788\n",
      "f1:        0.16008893829905504\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(grid_searcher2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 1.0}, 0.12855780953810678)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default learning_rate=0.1\n",
    "grid_searcher2.best_params_, grid_searcher2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgb = LGBMClassifier(random_state=42, n_estimators=300, num_leaves=63, max_depth=-1, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8755590634043673\n",
      "recall:    0.38579234972677595\n",
      "f1:        0.1992099322799097\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(final_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One more final LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase num_leaves from 63 to 127 (didn't improve)\n",
    "# increase n_estimators from 300 to 500 \n",
    "# it made recall and f1 worse so I return previous param-s \n",
    "# then I increase only n_estimators and came to clue \n",
    "# that it does not improve metrics\n",
    "final_lgb_two = LGBMClassifier(random_state=42, n_estimators=500, num_leaves=63, max_depth=-1, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8755590634043673\n",
      "recall:    0.38579234972677595\n",
      "f1:        0.1992099322799097\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(final_lgb_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance between default lgb and improved lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var38</th>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var15</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_hace3</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_hace2</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_var30</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_var45_hace3</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_var5</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Importance\n",
       "ID                             337\n",
       "var38                          296\n",
       "var15                          272\n",
       "saldo_medio_var5_hace3         146\n",
       "saldo_medio_var5_hace2         121\n",
       "saldo_var30                    104\n",
       "saldo_medio_var5_ult3           98\n",
       "saldo_medio_var5_ult1           92\n",
       "num_var45_hace3                 85\n",
       "saldo_var5                      79"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var38</th>\n",
       "      <td>1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var15</th>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_hace3</th>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_medio_var5_hace2</th>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saldo_var5</th>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_var45_ult3</th>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_var45_hace2</th>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_var22_ult3</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Importance\n",
       "ID                            2358\n",
       "var38                         1846\n",
       "var15                         1699\n",
       "saldo_medio_var5_hace3         643\n",
       "saldo_medio_var5_ult3          457\n",
       "saldo_medio_var5_hace2         368\n",
       "saldo_var5                     320\n",
       "num_var45_ult3                 297\n",
       "num_var45_hace2                260\n",
       "num_var22_ult3                 248"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance(final_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning model with  'scale_pos_weight' (default=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_pos_weight = sqrt(count(negative examples)/count(Positive examples)) \n",
    "# sqrt 96 / 4 = 4.899 - isnt better than final_model_two which has recall and f1 of 0.38 and 0.2\n",
    "# but with scale = 5 makes model's recall 0.51 but f1 0.12 and accuracy is 0.70 \n",
    "# with scale = 6 accuracy, recall and f1 are 0.65, 0.63 and 0.13 \n",
    "final_lgb_four = LGBMClassifier(random_state=42, n_estimators=500, num_leaves=63, max_depth=-1, learning_rate=1,\n",
    "                                n_jobs=1, scale_pos_weight=4.899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8868718758221521\n",
      "recall:    0.17923497267759564\n",
      "f1:        0.11279229711141678\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(final_lgb_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgb_five = LGBMClassifier(random_state=42, n_estimators=500, num_leaves=63, max_depth=-1, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid4 = {'scale_pos_weight' :  [1, 4, 4.899, 5, 6, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher4 = GridSearchCV(estimator=final_lgb_five, param_grid=param_grid4, cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6960010523546435\n",
      "recall:    0.5158469945355191\n",
      "f1:        0.11984257966230799\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(grid_searcher4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'scale_pos_weight': 5}, 0.15081468357248878)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but with this parameter model isn't better than with defalut parameter (=1)\n",
    "grid_searcher4.best_params_, grid_searcher4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Is_balance'=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of scale_pos_weitght I try 'is_unbalance = True'\n",
    "final_lgb_six = LGBMClassifier(random_state=42, n_estimators=500, num_leaves=63, max_depth=-1, learning_rate=1,\n",
    "                               is_unbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6426817504165571\n",
      "recall:    0.6426229508196721\n",
      "f1:        0.12611260053619305\n"
     ]
    }
   ],
   "source": [
    "# with parameter 'is_unbalance=True' results are as the same as with 'scale_pos_weight'=6\n",
    "fit_and_result(final_lgb_six)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning model with bagging_fraction (default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgb_seven = LGBMClassifier(random_state=42, n_estimators=500, num_leaves=63, max_depth=-1, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid5 = {'bagging_fraction' : np.logspace(-3, 0, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher5 = GridSearchCV(estimator=final_lgb_seven, param_grid=param_grid5, cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8755590634043673\n",
      "recall:    0.38579234972677595\n",
      "f1:        0.1992099322799097\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(grid_searcher5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bagging_fraction': 0.001}, 0.13569482223375434)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searcher5.best_params_, grid_searcher5.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning model with 'boosting' (default='gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgb_eight = LGBMClassifier(random_state=42, n_estimators=500, num_leaves=63, max_depth=-1, learning_rate=1,\n",
    "                                 bagging_fraction=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid6 = {'boosting' : ['gbdt', 'rf', 'dart', 'goss']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher6 = GridSearchCV(estimator=final_lgb_eight, param_grid=param_grid6, cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-ny46z16n/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9341401385600281\n",
      "recall:    0.14426229508196722\n",
      "f1:        0.14949037372593432\n"
     ]
    }
   ],
   "source": [
    "fit_and_result(grid_searcher6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'boosting': 'goss'}, 0.13985023089072035)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searcher6.best_params_, grid_searcher6.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
